{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Activation Function\n",
    "\n",
    "As funções de ativação são funções que decidem, dadas as entradas no nó, qual deve ser a saída do nó. Porque é a função de ativação que decide a saída real, muitas vezes nos referimos às saídas de uma camada como suas \"ativações\".\n",
    "\n",
    "A entrada para a unidade de saída (output unit) é passada através de uma função de ativação, $f(h)$, neste caso, a função de etapa (step function):\n",
    "\n",
    "\\begin{equation*}\n",
    "f(h) = \\begin{cases}\n",
    "0 & \\text{if $h$ } \\lt \\text{ 0} \\\\\n",
    "1 & \\text{if $h$ } \\ge \\text{ 0}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "A unidade de saída (output unit) retorna o resultado de $f(h)$, onde $h$ é a entrada para a unidade de saída. (The output unit returns the result of f(h), where h is the input to the output unit):\n",
    "\n",
    "$h = \\sum_i w_i x_i + b$\n",
    "\n",
    "Ficando a formula completa do neurônio (perceptron) da seguinte forma:\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x_1, x_2,\\ldots,x_m) = \\begin{cases}\n",
    "0 & \\text{if } b + \\sum w_i . x_i \\lt \\text{ 0} \\\\\n",
    "1 & \\text{if } b + \\sum w_i . x_i \\ge \\text{ 0}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "O diagrama abaixo mostra uma rede simples. A combinação linear dos pesos, entradas e bias (w, x, b) forma a entrada h, que passa através da função de ativação $f(h)$, dando a saída final do perceptron, rotulado como $y$.\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/589366f0_simple-neuron/simple-neuron.png)\n",
    "\n",
    "A melhor parte sobre esta arquitetura, e o que torna possíveis redes neurais, é que a função de ativação $f(h)$ pode ser **qualquer função**, não apenas a step function mostrada anteriormente.\n",
    "\n",
    "Por exemplo, se $f(h) = h$, a saída será a mesma que a entrada. Assim a saída da rede neural é $y = \\sum_i w_i x_i + b$ pois $y = f(h) = h$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Outra função de ativação (activation function) usada é a logistic ou sigmoid:\n",
    "\n",
    "$sigmoid(x) = 1/(1 + e^{-x})$\n",
    "\n",
    "Desta forma, a saída do perceptron fica:\n",
    "\n",
    "$y = f(h) = sigmoid(h)$\n",
    "\n",
    "Onde:\n",
    "\n",
    "- h = $\\sum_i w_i x_i + b$\n",
    "- w = weights (pesos para cada i)\n",
    "- x = inputs\n",
    "- b = bias\n",
    "\n",
    "A implementação em Python fica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "0.432907095035\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "inputs = np.array([0.7, -0.3])\n",
    "weights = np.array([0.1, 0.8])\n",
    "bias = -0.1\n",
    "\n",
    "# TODO: Calculate the output\n",
    "h = sum([(w*x) for w, x in zip(inputs, weights)])+bias # Input\n",
    "# Poderia ser feito com h = np.dot(weights, inputs) + bias\n",
    "\n",
    "output = sigmoid(h)\n",
    "\n",
    "print('Output:')\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sum of Squared Errors (SSE)\n",
    "\n",
    "A rede neural ajusta os pesos buscando minimizar o erro da previsão o máximo possível. Para isso, é usado o SSE.\n",
    "\n",
    "\\begin{equation*}\n",
    "E = \\frac{1}{2} \\sum_{\\mu} \\sum_{j} [y_j^{\\mu} - ŷ_j^{\\mu}]^2\n",
    "\\end{equation*}\n",
    "\n",
    "SSE é a suma total dos erros de uma rede neural onde:\n",
    "\n",
    "- $ŷ$ é o valor da predição\n",
    "- $y$ é o valor real\n",
    "- $j$ representa as unidades de saídas da rede neural\n",
    "- $u$ representa cada data point\n",
    "\n",
    "Primeiro, a soma interna sobre j. Esta variável j representa as unidades de saída da rede. Então, esta soma interna está dizendo para cada unidade de saída, encontrar a diferença entre o valor verdadeiro y e o valor previsto da rede ŷ, então faz o quadrado a diferença, em seguida, soma todos os quadrados. \n",
    "\n",
    "Então a outra soma sobre μ é uma soma sobre todos os pontos de dados. Assim, para cada ponto de dados você calcula a soma interna das diferenças ao quadrado para cada unidade de saída. Em seguida, você soma essas diferenças ao quadrado para cada ponto de dados. Isso resulta no erro geral para todas as previsões de saída para todos os pontos de dados. \n",
    "\n",
    "O SSE é uma boa escolha por algumas razões. O quadrado assegura que o erro é sempre positivo e erros maiores são penalizados mais do que erros menores. Além disso, torna a matemática agradável, sempre um plus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "A previsão, ou saída da rede neural, depende os pesos pois a previsão (saída) é igual a $f(h)$:\n",
    "\n",
    "\\begin{equation*}\n",
    "ŷ_j^{\\mu} = f(h) = f(\\sum_i w_{ij} x_i^{\\mu})\n",
    "\\end{equation*}\n",
    "\n",
    "Sendo assim, o erro também depende dos pesos:\n",
    "\n",
    "\\begin{equation*}\n",
    "E = \\frac{1}{2} \\sum_{\\mu} \\sum_{j} [y_j^{\\mu} - f(\\sum_i w_{ij} x_i^{\\mu})]^2\n",
    "\\end{equation*}\n",
    "\n",
    "Logo, ajustar os pesos influencia no total de erro da previsão. Para encontrar os pesos que resultem no menor erro, usa-se o **gradient descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Gradient Descent\n",
    "\n",
    "Gradiente é outro termo para taxa de mudança ou inclinação. Para calcular a taxa de mudança usamos funções derivadas.\n",
    "\n",
    "A derivada (taxa de mudança inst) de uma função $f(x)$ retorna outra função $f'(x)$ que nos mostra a inclinação (coef. angular) no ponto $x$.\n",
    "\n",
    "O gradiente é apenas um derivado generalizado para funções com mais de uma variável.\n",
    "\n",
    "Para entender melhor o que é uma derivada seguem 2 videos rápidos sobre o assunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkz\nODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2MBERISGBUYLxoaL2NCOEJjY2NjY2NjY2Nj\nY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY//AABEIAWgB4AMBIgACEQED\nEQH/xAAbAAACAwEBAQAAAAAAAAAAAAABAgADBAUGB//EAD4QAAICAgAEAwUHAwIFAwUAAAABAgME\nEQUSITETQVEiUmFxkQYUMjM0crEjQlMkgRVUYqHBFkSSNUNzgtH/xAAYAQEBAQEBAAAAAAAAAAAA\nAAABAAIDBP/EACERAQEBAQADAQADAQEBAAAAAAABEQISITFBAxNRMiJh/9oADAMBAAIRAxEAPwDf\nRTW6K/6cfwryLPAr/wAcfoNQv6Ff7V/A+jwPdirwa/8AHH/4h8Gv/HD6Is5Q66FqVeDX/jh9CeDX\n/jj9EW8pOUtSnwK99a4a+SMl/B8O9typUW/OPQ6OgaHaZc+OBl/Z2mNM5USk5pdI+pRw7gEpOTzI\nuK8kmem0BofKt/2Vhp4Xh0/hoi36vqaPAq8q4L/9S0BbXPbVbpr/AMcfogeDX/jj9EXaBogq8Cv/\nABx+iB4Nf+OH0LgaJYodNf8Ajj9BXTX7kfoXtCNCMVeDX7kfoB1Q/wAcfoWaAKVuqHuR+gHVXr8E\nfoWaA+xBX4UPcj9CKuv3I/QcEmltt6S9SQKuHuR+gfCh/jj9DBPjeDCzk8ZN+q7HQrsjZBSg9xfV\nNDi2J4VfuR+gfCr9yP0GCCJ4VfuR+gfBr9yP0GCRVuqv3I/QDqr9yP0LNAZBX4dfuR+hPDr9yP0L\nNAJK/Dr9yP0FdUPcj9BcrJrxoJzfV9ku7EozK7ZcmpQl6SWthqxY64e5H6CuuHuR+hZKUYpbaW/U\nG+nTTTHRhPDh7kfoTw4e5H6DMXnhy83Mteb32JB4cPcj9CeHD3I/QllldUOac0l6sbaa2ntFqL4c\nPcj9AeHD3I/QFV9d2/Dmnp6YbboU8vO/xPSHVgOuHuR+gHXD3Y/QayyMI80mor1ZFpra6ogTkh7q\n+hVkctVbnGrnfokWO2vxVXzLmfkZ8vNqxpcr25PyLThaJ2WT9vGjCHqzRyQ91fQCui6fFXbWzFVL\nJyVK6NqhHyWi1Y3ckfdj9AckPdX0K8S53Uty/FF6ZaQLyR91fQnJH3V9BiEi8kfdX0ByR91fQcmi\nBOSPur6CuEfdX0LNAJK+SPur6C2Qj4cvZXZ+RcV2/ly+TIvR0L/T1/tX8FgtC/09X7V/BZo4frtC\nrew6DoOhRQaHaAyRNEaG0UZmXRh1eJfNRS7fEQsAzjP7SUqSbx7lU/8A7nKdiqyF9cbK5c0Zdmhy\nxamiDgBFIQgoCaCAkSSEZYxdCCCtDiTnGEXKT0l5iCWSjXBzm9RXdsw4PEVnX2Rrg/Dh/f6sqy8z\nB4gpYf3jTk9bRtw8SvDoVVS6d9+pvMntn6uM+bjvJxp1Kbg5dNo0sqyJSjROUOsknpBC8xn4OJRG\nOLjxduVLz32O/wAIxrMTAhVa9z7/ACOJwLLx675eOn95sl3aPUI11fxnkTn5fE5Y8pLwJ6T1zPsd\nJdjm8cTeGl/1o51uLKMm/wACWRkRjGvl5lruNh8Spy7XXDmTS318xM6Mlwbkgm3yRWkcnBwcxWV2\nVpwUv7vRAcjp5vE/u87KuRqa/DJ9mC/iLq4dCyfS2yPs69QcXx5200VpOdm+stFXEMK+2nFg4qTh\n0lry7EcaOF533qrlskvFXl6m0xcPwHi22Sklp/h0b9Czfrjcfrl/SsT+Ac98lWLy/m9Opr4pizyq\nIxraUlLfUqxeHzjcrcmznkl0Xkiwyub4qnlWfeVZPXZROzRCMaI8iaWuzOe8XKqyrfCiuWx/j9Dp\n0QddUYyk5Nd2OCo0cF2Ouq6lt80p9j0Jjs4dVPIVz3zeaXYqI5fFZyTpp2/Zgtmzh2RbbQouHsxW\nuZmqeFCeUr35LWi2umFcXGEdJlhtjzlMMmLlbRzey+rRurz7JuhTjF8z020dWNMIJqMUk++hI4tU\nF0rXfa+ALWHjnTFjFecirDnlSxXKNkdQWtNdTp341eQo+IvwvY0aoV75Ypb7iNcjDuojJ23y3bJ6\nXwK8+qeTxHkrf9vdmrOxefLpjXWlHe5NI6HhxT3pbXTeiO45PD8Z21WKc3tezrZI05dVTx4RXK3+\nL4HTjWoN8qS2ERqjGo8ClQ8/NluhgEyVgGYpJCBIyQCjABAJb+XL5McSz8uXyYh6ahf6av8Aav4L\nNC4/6er9q/gsZw/XcugjLsDRIpNDaASJJqMW29JI8zjRXHuM22WdcbHeox8meizlJ4V/J+Lkevoc\nT7HqH3C1r8zxPaOnPqWs37js2YtVlMqeRKDWtaOP9m7XF5OFN7dE2o/I7d9sKK5WWdIxW2cD7L1y\ntty82S6Wz6DPcqv16DQNDEMFxuJ8co4dYq+V2We6n2NPDeIU8Ro8Sro1+KL7o8xxCz7jxzJtvqcu\nZPkNf2NjKU8qzfTotfE6+E8dc51bcbnx2PPmQ5EnQvZe+42LxiMuDvMvSTT1pebMPEPs3ffxCdlN\nkY12PcupszuC83BliUNJw9rr5sc5Xt527judfk81dkoLfswiexxJzsxa52rU3HbR5jC4dxGu+EVj\nVw0/xtHrEmklLv5j1n4poNHmOP5F+TmfcaXypLb29bPUM5fEuDU58/FbcLO20Z5zfZvuPL1YEsay\nFuVZGEU+ye2e0qmrKoTj2kto5eN9nceqalbKVrXvHWSSWktI11dZ5mAyaCyGWmSGNifeeZQr8Ven\nc2aMNHDYVcQnlqcnKXl5G9FREQttULo8tkVJd9MfQTLQcq5deQdBRNEg0QTJtdNMpqLk15INc/Eq\nhPTXMt6fkSHQrGAQL2AJbfVX+OaT9BnKPKpb6P1FAwaFjfVObhGScl5IdkAIEDaT69CSaEsnGqEp\ny7JCzyaq5alZFP5lOdbUsVub3GXbQHFmNkRyqueCaW9dS7RihOrCw/FinyS09FeJxGWR475UowW4\nstOOgxe5lllzhg+PKPX0JjZcr2tVNL1Y6MamugujNxHLeNV7P45dh8PIWRTGTa5vNFoxboGhgMQX\nQo4pIGhdDEJFIEAINEYQEgEt/Ll8mOJZ+XL5MQ9Tjr/T1fsX8FuhMdf6ar9i/gsR5/13LomhwES6\nBocAojW4tHmcvgWbjZU8jhdvKpvbhvR6jRGanWCzXlYcI4rnzjHiN/LUn1in3PRUUQx6Y1VR5YR7\nFwGug3rRJgCsYDAsuVVRODdsYPp/ccH7I6V2dFdlNa+rN3GuEX8RvhKGS660tOJPs/wqzhqv8V75\n5dPkjpPXLGe3W0K0WMUyVQH2Ha6iskV9hWP3FfcQUUZiiA0QLegbJIl1GRAokhAhIoiECCZOJX+B\nhWSi9Sa1H5mG++7E4NU3J+LLszo5eLHKhGMm0ovevUp4lgPMhXFT5eR9gMxXDLk+FRvm0pOP/ceU\n7ngR5JLxZLpsyQwMlyhRZJeBB76G3Lwo5MIx55QcezRYtjDwuuFrslb7V0Jddjcaq5saM+aSaekk\n+hsw8OGJBqLbk+7fmHLxo5FSg5a09j+Lfbn2Qhw/A8SC/qtJbfqU8N4jpShkOTbfRnVvx6761Cxb\nS6lFeIoZUp8seSS+hYtjNfmy/wCJVVVz1X/cy2UnlZnLF/04d2iW8MqssnYpSUpdvgXYeKsatrfN\nJvbYYtjnrDg+J8iblFLb2Z76bbsu5VL2K/J+R2ljxWS71+JrTLFXBNtRScu79RxeTi2Sts4VCLjv\n2tA+6X4/LCCfLYlvR2o1whHljHS76CWLyYOJQ5cBQXZaM2HK6d0I+LzRj6HWnGM4uMltMSumupar\niolg30wXYzy89+Kn4cF0+Jbh4axpTfq+nXyNoGODyKAIBZQQcQkBAgBAyJBB2JIDQdgJA0Jb+XL5\nMsYln5cvkxD1WN+mq/Yv4LSvGX+mq/Yv4LGef9ehABI0SKQhPIkBGEgougaC0DQgNC6GFFATS0Eh\nArEY7QoojFaGfcVmgUV9xgPuQKxRmBiisGgsggV3CAZAkCAK7gR0EBCAgaCBkitACAkDAwyAKI+w\nBtAIIKMQkBA+YGSKBjPsAkAAgJABjMAghGMxQQAaCQURgHACKBjAJFIMwEgEt/Ll8mOLZ+VL5MU9\nXj/p6v2L+CxleP8Ap6v2L+Cx+R5/12QhAkS6JoJBRdAGAyQMAQCCMAzOB9peKXYSqrxZJWyfVa30\nGTbgtx3CHk+DfaS2eRGnN01J6U0ux6zv1NXnBLqeQjQ4r7BCRiNdR2KIIK0OLIQRgYzFa6iisgWA\nQiYyFXcZEhIu5BtAkCREBIBhICLoAwooGgaCwCivsBhfYBANECAkBGRgJJsBCCk0AW26urXPJR32\n2N3XQEDRNBASBitDMHmSLoAwCBWgDA0KABCEkF0MAkAtv5cvkxxLfy5/Jknqsf8AT1/tX8FjEx/0\n9f7V/A5w/XZAgIREAQEkIyEZArQrHEaFFl2POYmBbl8UyczMrfLHca4v+T0hXP8ABL5GubgseO+z\nnDcfNtyfHjtwl00+x7KMVGKiuyWjzP2QX9XMf/UenfQ13fY5+FFYwrMkrFYzFEEYAvsAQVisdiN7\nEFkALAIBdx0Ku4yfwImXYIqYwIUECCCQVjAZIBRgPsSKxWMwCgAw6I0SKQjIQBgCwEkAwgZJxeOU\nq7KxYTbUZPXQu4Z41F1mNZuUY9Yy+BOOJKmFqa5q5Jo0Yudj5EtVzi5620jtt8HP9awEAcXRGBhY\nH1IFAxgMkUgQEgFGBrQoCMmiAAZXb+XP5MsYlq/pz+TEvV0fp6/2L+CxldH6er9i/gsZw/XYAgIS\nEhCEgIEBIBX2GFYoCuf4X8ixiS8xTzf2R6WZv7z0jPNfZL8/N/eekkb6+sz4VgYwrBFkKOxGSIBj\nCsQD7CtdBhWIKK+4zM2bmVYVLtsevRebNCq+IZ1eDQ5ze5P8MfUq4M8yyuduXLpY9wj6GPAwrc/I\nWdm9v7K/gd6K6dtDfXoQyXQIBjDSBAEEgGEjFFA+wfMgIoBmKxQA8wvsAkD7gGISIQJk4jlxw8dz\nenJ9EviMm+hbjSQw8IjkLGcshtyk9r4G8rMql1zeJ8NjmpSc3HlXkY/s9RVyTnyasjJrZ3G0l7TS\nRleVj0tqHV+kV3Nf2Xxwf17djRJxjHcmkl5sWE42x5q3tepmVU8t81qca12j6mqFUKocsFqK8jn9\nbskR9gDFcLYW75JKWnp6FnBAMxdMgDIEV9xSAYSAigCwEgYtv5U/kxhbfypfJinqsf8AT1/sX8Fh\nXj/p6/2r+Cw4OwB0QJICEISQDCAkAoWAUDEY7FfYQ8z9lfZzc+t9+b/yelaPM/Zr/wCsZ/zf8npz\nfX0c/CNCsZivuBBijCsWSNAY77CMUAjfQYoyboY9UrLJajFdRgJmZVeLRKyxpJeXqcbDxrOK5Cy8\npapX5dZKa7eM5KvuTjiwfsx947sYRhFRikkvJG/jP1I9NJdEOimdsKluckl8TBmcexsaSjDdr/6f\nIJzevi2R1hjzy+0sJdseRbH7S0b1OmxGr/F3/g847iCc2njeFbpeJy/uRuhkVWJck0/kznebPrUs\nq0DIgsy0XQGFivsIDewBISBg0EDBBoBVdl0U9J2LfourMz4hKb1RRKXxfYta8LW2bUYtt6S9Tgqy\nHEeJOyySWPT22+7K+IZWXkWrEjP2pPUlHyOlh8Iox6YqScpLvtnWbzNZsm5atlmwT1VGVnyQN5lv\nXUal9Wa4QjBajFL5C22Qqg52SUUvNnLG5Z8kZ1gxk+a2yU/h5F0KK6/wQS/2JTdXkQcq5bSEjl0z\ntdcbIufoXoW9VbrXYnmZsvLePZCtR55zfYpyeKV0W8nI5Nd9PsWicdVu8jkW3wxOJPl6xmvaUfJk\ns4rZZPePDUIrbTHyaa540cmuGptqTK11558f+lmfmeBVFx6Ofb4FXDrMqyzmsbdf/UW50XKNN/Jz\n8vdBx8v7xcowqcYLz9AXzn1GrzA0NrQDTzlBsbRNIkUUZkfYUUS38qXyY4lv5UvkyD1WP+nr/av4\nLCuj9PX+xfwWHB3QINBJAQzZ2ZDEgm05Sl0jFeYmPZlzalZXCMH5b6gcbAMVWwlNwjJOS7rfYz52\nbDDhCU4t80tJIQOZl14kYytUuVvW0uxZGUZxUovafZgshDIpcZLcZLszncMm8fItwptvle479C/T\nnp02JJ9Njt7El2Ztl5f7LTdnE86eu73/ANz1B5f7Ja++Z3z/APJ6g319E+A+4oX0FMoJCjPqK10G\nIoGErtsjXBzm1GK7tkCW2wpg52S1Fd2cDlt45k88tww4Pp5cxMi+XFbZbl4WDX1cn/cVzz7cnWLw\nyrUF059HfnhztdLI4jiYFarTW0ukYrsc2WfxLiD1i1ckPU14XAq6/wCplS8Wx9evY6qrjBJRikl5\nJDvPPz2MtcGHAr7pKWXkt+qXU21cCw4LrBy+bOiRdDN/l6PhCU4mPQmq6ox/2HlRVJalXBr4oYOz\nn5VvGO3hGFYutKW/d6GGz7PuMubGyZw+DO3sHMan8vU/R4SuC48YwesX40PqXUfaGG1DKqdUvVI7\nG1r/APpky6cO2P8AqI1/N9x/s5v/AFBOOvxfTlU3x5qrIyXwY0LYWJ8klLXfR5TNxo0zcuH2WfJL\n/wAmLB4hfjZDTnKPM/aZm8y/81rLP+vT3EpJLbel8TNZn0QelLnfpFbMlFNOTFTnkO74KXQ1wpqq\n/BCMf9jlbY65zP8A6pllZFj/AKFGl70hZYmRf+fkPXux6GzmK7b4VR5pzUV8WQ88+QlWFj0dVBSf\nrIx8U4j4b+7YsVK6Xp5GfL4vPIn93wYuUn/cjTwvhyxd22vnul5vyO0k4m9OXXV6W8K4esSvnn7V\n0+smzorsV8wdmL1t2mTBfY5vGEpKpcy3F75X5nRKr8erISVsFLQNcXLrLZer+GzljLTXRpLsZMCN\nMboeBVKdn90pdOU6tGPXj1uFa0n3LEkt6SW/RFjfnJsc/NwrrslXVWJPWupbXg0xiueEbJ+cn5ms\nBMf2dZiiGLTCU5RglzrTQ6hGMVFJKK8hyaFi236VpaBpeSSGFIAAOgCkAwgZIrAEBJBLfy5/JjiW\nflT+TIPVUfp6/wBi/gcTH/T1/sX8FhxdgCQgFg4pUpVxt11raka4S564uPZoz8Vc1g2ckoxeuvMY\neB02WVRvstk11Sj5IP1r8Hh0ZTzc171Pek/Q5+TdkLLqozG5cstqSXdHXnh215jvx5R1P8cZI0Sx\na5ZEbmvbS0hxazV8Q3xB4sq9JrcZepVPGujxmORFJ1OOm/Q3WY1U74XOO5x7MsGRnQMebblQklj0\nKxNdW2bJdxJdjQrzH2Q28nNb6PfY9OzzP2Rf+pzv3f8Ak9MzfX1mfA7ijbFfYyQfRisLEnJKLbek\nhRbJqEXJvSXc81n5r4la64TdeHW/bm/7irjfGPvNjxseX9JfikvMfh3CrMqEJX7hRH8MfU788ZPL\npyvW+oRxnxLlxMOPh40O8n5nexMSrDojVWl0XVl1VUKYKFcVGK8kF9A6731DOf2oxW+oJSElI5tY\nLa2TmKpzjFblJJfFmafEaYPUW7JekUZ1uc2t3MHfqc55GXdp1UqC9Zh+622db8iT/wCldEZ1vwn7\nWqzNoq/FYvkjO+IWWPWPRKX/AFS6IerGpq/DWt+r6l2/9gtP/mfjL4eZd+Zaq0/KI0cGqL3Pdj9Z\nMv5ugspGdXlRSjFajFJemjlRwaLs/JVlfsaWvI6fMU15EbLbKkvah3KdWfGbN+uVZwi/Hn4mFc18\nGwLiPEcV8uRRzr10doWctRbfZHT+7/Zrn4f44P8AxniF0/DhWk5dF0LYcJycl8+ZkPXfSZ0MbK8e\ne4UNQf8Aeaudb1vqN/lz/mYv6/8AarxcWjEgo1QS+PmzRzMq3syZ87KowthJpRfVepz8r19a8XQU\ng83Qprs54KXqtjc2y1Yt5inKy1jRXsuUpdkhtsz5q5YQs9ySZrRi7GybLZONtUq3ra9DRsrjJSSa\n9DLTkXX5slFpVQ6P4josbyFc7Y11ynJrlj3BRdC+pWVv2X6iFeTk/dnFutuDem/QuUlJJrsxb61b\nTKt9mjNw6blj8ku8Hol+NYoQCyBCEFAAJCBRR33FIgLZ+VL5MYW38qXyZB6nH/T1fsX8FhXj/pqv\n2L+Cw4uyEAQiS2qF1bhZFSi+6ZKqYU1qFcVGK8kOEkQAWAkANhfcrVkJ75JKWn10aAtiT7MYWf4R\nDzP2R/U5v7j055j7I/n5v7j0xrr6J8DzA+wSudkYrq0l8QiGbSW29I8nx/jMrZvExG/SUl5/Av4/\nxhyl9yw3uUukpLy+A/B+Bxx4K/KSdj6pPyOvPMk8umLbbkUcG4Kq4xvyY7l3UX5Hd59dCm/Mx6l1\ntTa8l1ZjnmXW/pseT+Muhy77vVduP4sjo+IU25dVf45xj/uYJ05Vv5tvIvSAIYdEXuUXJ+smY1vw\n5n2rJ8Ti3qiudj+HQRzzru7jVH6s0R5UtQSS9EBsdGyfIzLCi+ttk7H8WX1111/gioi8xEw0bav5\nn5MbZUn0GTM2rD7DsRPZNhpHYAkAgYMSuUc/Jk4tJvozeU0ZMbrbYRXWD0ygW6FsaUXvtocz5dMr\n4KMJuEk9pop9THwzJjqVPVdXroLjzs58i6K5pp6SNWHirGg+Z7lLq2SGLGu+VkZNb6uPkatiZ8TL\nsyMuX9sEusX6mjJStxbIxafTyFqxIVSnJN80vMTh1cqq5xnHT5vPzL1+JdhS5sSHXqlplU/v0rGo\nuEY76M0xiorUVpfAZBoNDelzPb0Y+KWbpcY28rXVx9TXsz5GHVkSi57TXmhlA8OdzxU5yUlr2fUr\n4fbXWpxskozc+z7s21pQiox7JaFdFTmpuC5l5mmdc3iMHXeowlNxs6yj6GuzOrxIVV1w5lrt2NnK\ntqWk366M+ThVZLTl0kvNM0Nn60VWxurjOPZmXD9nKyIfHZqqrjVXGEeyKacbw8qd/Nvn8vQQ0AYU\nBiyBAgFAQICQPuBhfcBIBLfyp/JjiW/lT+TJPUY/6ar9i/gsKsb9NV+xfwWnF2QhNgJCc2/iFzy5\nUYtKscPxNvR0Tmzj914op/23LT+YUxurlOUIuceWWuqDsx8TzJYlMJQScpSSWxsnOqxIwd+1zLyX\nRCMXxtrsclCak49Gl5HKzseWFa8zE2kvxw8mUcMyqaVlZVk9RnPobKM+nPjZQoyhNp6UvNEcxqou\njkUxtj2ktjT/AAsxcIqtpxp12xa5ZPW/QbPux/u84W3qCfuy6mozZfxwvslNLLzItpNy6HqGeJ+z\nslXk3zhjyvmn7PwPSNcSyOrlCiPourN9/Tzx/wCd1unZCH45KPzPE/azif3nLjTTZuqC66fmbeOW\nVYi8FWyvyZd9v8Jir4BbPFhfZBuU3+FLqkb45z/1XPvL6lZOCPIrlZfVTzqK6yf9p3MSy/iOQld4\nkorvp6SO1jYFGNgvHrrUFKPX1PHysyeCcVkttwT7PzRWedPPV4j1GRhqnHk8SuPir1M1d+bOSU8V\nKPm99jRgcUoznywa5vQ1yXp2OdmNeVv1jnHZz755atarqg4+rZ1Zx6meyPmZOubz53+Ov6ltLu5H\n43Kn8C+SK9proZKSb5XrWzIlnN/jgjUFPRJnUM563bBf7G+O1FbfXzM8741x5ptJFVefCd7qin0W\n+bZZadXZFeRZNOm1Qj8itY2W/wD3X/Yt8YaNwe0fFqsqi/Ftdjfr5FtsXOtxjLlb8/QSFiZZzIym\nD/h9r/FlTDiYDx75Wu1y35G3nivMr8WI7UsA2hVNPsyNmUgGTYGCAhGDYpCAbBsgdMKZWTYwLUx+\nYo2HmNRVdzBTKUxkzbC5BYnN1Ds0yJAE2aQgJshBBZBA+pABhdBJBIrt/Ll8mWMrt/Ll8mSejwrY\nzx60uklFbT79jQcudqWFG1dJwgmpevwN9E3OiE5LTlFNo5Z+u0q3sAmwAROP9ocqFVUI9fFUlJdD\nrbMfE8WWbjeFGSi97ba8isU9Ofm2W5WBTfKpx5JKXzRvhdRxCmcI6ktae0X1VqrHjV3UVoMYRgtQ\nikvRIcVrnVcGojjuqftbe9p9jDGq/FzZLFx5zmuniTfTR6AA4Z3jlfcs7J65OVyJ/wBsCyvhWJWm\n3Dnl6yezoMSXZjMXX8nVea+yH52al7xv45xiGDV4dT5sifZeh5zhnFP+GzzFGPNbOWoI6vB+D2XW\n/fs/bnJ8yizv4+9rhvrITgvBp22/fM7bk+qTPS9lryDoBjrryMmCeZ+1eK24ZEY7XZnpSnKpjkUT\nqktqS0EuezXzii+3ByFZU9a/7nsuF8XqzoKL0rEu3qeVvxnGyyiaanB9PiVYleRVfGytNOLOvUlY\nmx72SKJx30KqM7xKIymva11KrM1I89rvJXPz8i+iUq5acZ/hfoWYsfAxo88+/XqUZclkXc0uyWkV\nWblQqt709oPTWOlKSim29JFH3mqXaaMs7bHFJsocfRBkPi2ZNlVlMouW/QyYVsKISc/xMSUStwZu\nDHQWbW2ujXxLY3wk+kzk8oGmXjBjtxtfkwu6T8ziqycfMdZVi8w8Q6srZeojsfqYI5kvNIdZKfkH\nimtXSi+5pqyNrqzmePECyVF9GF5LtuaS6sR3Q9TjSytlcsgPBa7vOpLownAWZOHZlsOKTi/a6l/X\nVrtEOfDidWuqNNOVVd+BmfGjV3mEhCxIQBCQ7JzdBSJmoFsXsbZSmgqRqUWL0+gUynmGizUrFWkE\n5icwgxGDZBCEAHYpGJb+VL5MdiW/lT+TBN2DH794XfwKory/E9Ha7LS7GbBqjTiUxgtLkRpOfV9u\ns+AAIuwIgJsDEIAmwEkAED7CAfU5vGeKV8Ox2207ZdIx+JOL8Vq4fS/O2S9iC7nN4dwqzMt+/cSf\nNKXWNb7JHTnn9rNv+OV9lsaGXxSyy5bcFzJfE9v2PIfZhqHG8mPqnr6nrx7vsc/AAQJhoOwrGYrF\nOJxjArnbHKXRp6kVLBhGKfTZ0+J1ynhz5VtrqcymcvBim+yOX8tv46/xSI6Uuieii2lrzNPK5eYH\nV6s5S16fTAqurD4Zs8JCS0jWrGOdYjgapaZW49TUYrNKAjgamuojiLLPyCygaHEjgOjGRwE5TW4b\nEcNGtGM+tELZQFcdDowr2waY6QJehJW3pFMpPZdMokjcYqc4GxWTZvGNMpNFkLZQe4tplDZFJli1\n3sHiKs1Czo/U6S7d97PJRl12jrYHENarsfyZw74/Y1K64NiqW1tPaD0ORRsmwEFIHYpNkDcwVJle\nw7ELebYykUcwVIdGL1IKZQpDxls1rOLSbETCma0H2Jb+VP5MYS38qfyZJ6TH/TVftX8FhXj/AKer\n9i/gsZydQ2QjI30FAxQtgJAQhBCHL4zxWHDaPW6X4ImzNzKsPHlbbJJL/ucXBw7OK5a4hmx1CL/p\n1s3zP2s3/wCK+DcLtyrv+I8Q3KcusIPyPRduxmyOIYmHKMLroVy10RnfHeHL/wBzAbvSzHm+BT5f\ntJJespI9oeC4Zk1Vcd8ec1Gvnb5j1q47w7/mYGuoOfjokOeuN8Of/uq/qGfGcGNUpxyK5NLot9zG\nVpvFZhxuM4d9KnK6EH7rkWPieF/zVX/yLFq99Vo42VX4Vr1+Fm7/AIpg7/U1/wDyMGZk1XzfhzjO\nL91me56b/juVnctdhJ2teZXZLllrZXKW0c5Hfyxa7n6iSs35lLehXM14ryW85Ocz85Of4jjOr+bz\nCnsyytS8y6qe1sbFKt11I4iuXUKkZI8okoFjYGCUSgJKPQ0NFbRqCqGtFbXU0uJXKIxlmkVSNEol\nUoG5WKzyB5lsolbR0lc7E7itaCHuhRUx1IXWgEnRxOITp9mXWJ1asiu3rFnmtltds63zQbOXXGmd\nPTJpkObiZys6SepGzxkzjebGl20TZQ7QObBLnIm0Z+Zg52SaOYnMZ+YnMyTUpDKRkU2OpiGpSHUj\nKplikOs1emCx/wBKfyYil0JN/wBOXyZuUPUY7/09X7F/A+ymj9PV+xfwWJmK6C2DZNgICABBQlGZ\nlVYePK66Woot2ZszEozIRjfDnUXtLYwOPi03cbyvveUnHFj+XX6/E9BFKMdLokLGMYRUYLSS0kE1\nbokZMzhWHm2Ky+lSmlrezK/s9w3/AAf92dUhbVkeL4LwmrK4jkK2CdNcmtbO+/s7wz/B/wB2ZPsz\n+pz/AP8AId811aJI5f8A6e4b/g/7sP8A6e4b/wAuvqzqb0upXffDHqdtj1FGdp8Y56+z3Df+XX1Y\nf/T/AA3/AJdfVnRrsjbXGcHuMltDFtXjHKl9nuHa6UL6sy5nDacOnePDl69ep3ynIrVlTi13K+zz\nnN15K72136mD7xOqfLYdnOw51SbXVHIyK+dP3i4n5XTu77i6fPGtWa3B+Znlct9w4GV4bdF3WufR\nmXPxXRY3F7g+zNzn3jF7uasd69RXec97Gg99DfgxP5feNbtci6i9wen2MiTCzNkblrqxsT8x4yOX\nC2US6vJXn0MXl0nbo7JszxsTXRlsWYxrVgBdhjIAjRXKJd3FkhDO4plc4GhoVoWWOUSiSNtkSicT\ncrNjODQ7iDRvWQ7gYSdyRQ7IyCjJ6e49GbsbL37M+/qc/TDszeZVPTuqSfYmzm4+U46Uux0IzUls\n4XmxoxCEAoEBCQoIowAyY6kypDoQtUhpy/py+TKkSb9iXyZqMvW0P/T1fsX8D7K6P09X7V/BYDab\nBsGwEDbI30E2TYodg2QAo2wAJskJAbBsUx8P4dXgTunCTlK2XM9m5sAGP0JL2k12PPZ88mnWHdPn\nhOScZPuegMmXg15dtcrH0h5GbDK01JV0wjHskNzM5vE8jJxIQ8CG4a03rei3huVZk43NbHUk9fMV\nW/nRG00VAb0OCK761Lozk5XDYz249Dtd18TPNaYHXkOIYE6fbXkV1WrIp8KzuuzPVZFMLa3GSXVH\nks3Glh5L8l5HSXWfjFfU4T0UdjpWcuRVzL8SME4tM6SufUXV2cy15jaMqbi9mqD5o7RnqY6/x9b6\no6EkOLIzG7EhdKHmaa8xeZiY9dbl1fYbzKx5WOgsmL8wxvRijV6vqWteyHgfN0KJ8y2WPqZMKW6+\nvdGvocb9dZ7iuSFZbJbK2tEFUlspnE0tFcojAyTiV6NMooplHRuVmqmAdoRm2U7kIQkhNECSDsaM\nfJdb0+qKdAaC+07NVkbI7ixzj1WyrltM6VF8bV6P0OPXONauIQhgiQhCAoZCjIYKdEn+CXyZESf5\ncvkajL1dH6er9q/gd9iuh/6er9q/gdvoH60hNgAKQICCkAQGxAkBshJCEISHYGDZNiA5lza9EBMk\nuvwBFcsddxQvqTSXZA2TZBGI2MxJdERgqXkLavMy2zkp9HoWzMsqXWHMjneprpObTzOTxCuORFxl\n38i+XFIb9uuS/wB9mLJvhZPmrfcrf8a54/1xfax7Wn2JkVqUeeJoy4KyO/MzVWa3CR6Obs1y65y4\nySQa5uEi2+rle12KGjf1xvq7GvmUltCvr2KqZ9eX1O/g8OioKyxbb7HO+ned7HPx8KUvasWkWWVq\nPRHQvaitIxT69hjHVUaBos5ScppjTY3sbRrRjXss01z2jh3z716P4+t9LRJIYbW0c3RSVyRdJdSt\noRVLiVSiaZRKpRNRmsriVtGmSKpR6m5WKp1og7QujTKEAQSbYUxAoMRgxk4va7gQQTdRlp6U/qa1\nJS7M4pbVkTqfR7XoYvH+HXXIUU5MLFrs/QvRyswihkKh0QMiT/Ll8iIk/wAuXyNRl6ih/wCnr/av\n4HZXQ/6Ff7V/BYTQE2DfUggdg2BgFG2KybAxSbDsUhA2ybFISMAgGKEACEEYCMDfQkDYk30YzYk3\n0KmMd2+ca9LkBZrY1mnUeTr69nM9OZZSnvSMN1LR1Itb0zNla0a5uKxyZtraMt0X+OJruWmaceNV\n9ThKK2enm44dzXMhNWx5ZdzPOHK2XZNM8W9xfbyZHq2O/M7R56zdju8I4g7K/u9svaXZnDktEjJw\nmpRemis1mXxr0162ZXHqx8PKjl09fxruGUepmevTVuquUDRZoxulu2fNNr0NMrZLoCuzleityjWt\nc2zPO5t6iZvtubK68Jc3Yu8jl4s5x/EdCEto89mPTKLRW0W9waBVU0VyiXSQjiLLPKJXOJpaK5RN\nSssziI4l7QjRrRilxFLmiuUTUowhNkAzQMmOipMdMKjaJoiYQJVuL6GujMlHUZ9UZtA0FkqdqucZ\nx2mWo4tGRKqXTt6HWptjbHcTlecK5En+XL5EQJ/ly+Qxl6ah/wBCv9q/gs2U0/kV/tRYn0FCDYNk\n2SHYNkAyQgZACkCAGyBiATJsUINkMWflSqlXVV+ZN/Qi2NgOVdfk4M4SusVkZvWtHU3vRJNgbIzD\nlcShjXOt1yk9b6EJ7bG9iS7FGLlPJhKTg46fTZbJ9Cvwz1WS6WmTn3ApyJe2xFZ7J5bPb28/ET3I\nz5Pcth1bKckZ9TnXCY1vh3d+jHtMc3pnokcem+2Dzo2LS1H8L+Jyk5VTal0aOzgz1jS0uq6/Mx5d\nP3ir7xBafZo3z1+OPfP7GOaUlzIpaLIS8iTidnGpj3yx7VOL+aO5XfC6tTXmeeZdRfKron0Zmwc3\n8da3IjA51uRZOzp0LVW59d72PGlLqzne3on8aiNcp/i2X10JFsYpDbOd6tdZxICikW1z09FLkVuz\nlezONV04voHoY6MhS8zWnsLMZCSK2WSEaIEZXJFrEkLKmSEaLWgaNalDiI0aGiucRlDNJClsoiNG\n5WaQiDoDNAyZYmUoeLCxLABiwsy0Rotx7pUz6Pp5iaBok7tVisipJjT/AC5fI5nDreWzw32Z0p/l\ny+RjMrNejp/Ir/ah2yuh/wBCv9q/gZijJg2hdkJG2HYiYdkh2RsABA7DsUmyAtkAQkOzm5tORHLW\nRjxU3rXXyOhsDZYdxyrMDJyq3LIs9tdYxN2FZZZQvFi4zj0fxLtk2Mi8hMOZgxyrVPxJQaWuhtA2\nVmjWfGx1j1OCk5dfMeXRDtiS6lh325l6bsZXyy/2NF2lY9maVvkjz369fN9CnpFF3XuNzMrsfQI1\nax2mO1G20yWo9HLj0v4ddqXI+x0Y1wjHlS6M4EZuufMu51qrb7IKSitB3P1nn36c/iGK6ZuUV7LM\nqfQ7N1d9sHGUU0zkX0yos5ZI68da5d857VyQpY+ojR1ca14d/wDZL/Y2trRxk2ntG2nI54ab6nDv\nj9j0/wAX8nrK1NgcilWIDmZx1vR3MpnMWUviVtmpy53tdjyfjJep1IzcTk0Rk7E9PSOp0cTPca4u\nrefZGytLQyZzbsEVoOybJhU0KWtCtCFehJLoWisYGdoSUS9xFlE1KGZoBbKJW0blFI0RMbQGhCyB\nYUwZcjFKEYQS7AUply3RfxO3LrW/kcSrrbFfE7Mulb+QX6zXfpur8GC54/hXn8B/Fr9+P1IQ1jOh\n4tfvx+pPFr9+P1IQsWp4tfvx+ofFh78fqQhYtTxa/fj9SO2Hvx+pCFgDxa/fj9SeLX78fqEg4tDx\na/fj9SeLX78fqQhYtDxYe/H6gdkPfj9SEHFqeJD34/UniV+/H6kIGIPFr9+P1J4lfvx+pCDg0rsh\n78fqK7Ib/HH6kIC1zM+6KnqMl9TEprfdEIcOo9fN9G8SPqhJyT80QgSNazz16ozWa9SEO3Llayz1\ns6nDrU6tN9vUJDXf/LHN9tE7orommzFlwV0dtrmIQ5z073LHLe4vTI+pCHrjw36Qibi9ohArK1TG\nTbIQzjr5Uyg5eaLYQhHvpkIQ0/PFdjRRYn0bIQz3PTfFyrtr1QvMl5oJDhj0aHOvVBU16ohBwWjz\nR9UBuOu6CQmLVba9UK2vVEIQK9eqBtepCDiJJL1KZJEIaiL0A9EIaZpYvTL4ta7kIVi0dr1A5IhD\nOLTYunkQ2/M60px5X7S7epCBZ7Ztf//Z\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/CQxb5ZXeY3E\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fb0f40e1cc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('CQxb5ZXeY3E') # O que é uma derivada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAYEBQgHCAgIBwgJBQgHCAgHBwcHCAgHBwgHCwgODAsI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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/bGvYbU4Ax6U\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fb0ce9c6cf8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('bGvYbU4Ax6U') # Calculando a derivada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "O processo de atualização dos pesos ($w$) é feito atravez da [derivativa parcial](https://pt.wikipedia.org/wiki/Derivada_parcial) (para funções com mais de 1 variável) do erro obtido pelo SSE. O processo para chegar a equação de variação do peso é complicado pois usa mais de uma vez a derivada parcial e a [regra de cadeia](https://pt.wikipedia.org/wiki/Regra_da_cadeia). O mais importante agora é saber:\n",
    "\n",
    " - A váriação dos pesos ($w$) pode ser calculado como $\\Delta w_i = \\eta \\delta x_i$ sendo $\\delta$ (delta) calculado como:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\delta = (y - ŷ)f'(h) = (y - ŷ)f'(\\sum w_i x_i)\n",
    "\\end{equation*}\n",
    "\n",
    "Lembre-se, na equação acima $(y - ŷ)$ é o erro de saída, e $f'(h)$ refere-se à derivada da função de ativação $f(h)$. Chamaremos esse derivado de gradiente de saída.\n",
    "\n",
    "A implementação em Python fica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network output:\n",
      "0.689974481128\n",
      "Amount of Error:\n",
      "-0.189974481128\n",
      "Change in Weights:\n",
      "[-0.020318691802303994, -0.040637383604607988, -0.060956075406911982, -0.081274767209215976]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \"\"\"\n",
    "    # Derivative of the sigmoid function\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "learnrate = 0.5\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array(0.5)\n",
    "\n",
    "# Initial weights\n",
    "w = np.array([0.5, -0.5, 0.3, 0.1])\n",
    "\n",
    "### Calculate one gradient descent step for each weight\n",
    "### Note: Some steps have been consilated, so there are\n",
    "###       fewer variable names than in the above sample code\n",
    "\n",
    "# TODO: Calculate the node's linear combination of inputs and weights\n",
    "h = np.dot(w, x)\n",
    "\n",
    "# TODO: Calculate output of neural network\n",
    "nn_output = sigmoid(h)\n",
    "\n",
    "# TODO: Calculate error of neural network\n",
    "error = y - nn_output\n",
    "\n",
    "output_grad = sigmoid_prime(h)\n",
    "\n",
    "# TODO: Calculate the error term\n",
    "#       Remember, this requires the output gradient, which we haven't\n",
    "#       specifically added a variable for.\n",
    "error_term = error * output_grad\n",
    "\n",
    "# TODO: Calculate change in weights\n",
    "del_w = [learnrate*error_term*i for i in x]\n",
    "\n",
    "print('Neural Network output:')\n",
    "print(nn_output)\n",
    "print('Amount of Error:')\n",
    "print(error)\n",
    "print('Change in Weights:')\n",
    "print(del_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Mean Square Error\n",
    "\n",
    "Em situações onde são usados mais dados de input, usar o SSE pode resultar em atualizações muito grandes nos pesos (w). Para compensar esse efeito, o learning rate (taxa de aprendizado) precisa ser realmente muito baixa ou então pode-se usar a média dos erros, assim não importa o volume dos dados o learning rate continua em seu range normal entre 0.01 e 0.001.\n",
    "\n",
    "A formula do MSE é:\n",
    "\n",
    "\\begin{equation*}\n",
    "E = \\frac{1}{2m} \\sum_{\\mu} (y^{\\mu} - ŷ^{\\mu})^2\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Abaixo segue um algoritmo geral para atualizar os pesos com gradient descent:\n",
    "\n",
    "- Estabeleça o valor do weight step: $\\Delta w_i = 0$\n",
    "- Para cada registro nos dados de treinamento:\n",
    " - Passe os valores pela rede neural, calculando a saída $ŷ = f(\\sum_i w_i x_i)$\n",
    " - Calcule o erro (error term) para a unidade de saída: $\\delta = (y - ŷ)*f'(\\sum_i w_i x_i)$\n",
    " - Atualize o weight step: $\\Delta w_i = \\Delta w_i + \\delta x_i$\n",
    "- Atualize os pesos: $w_i = w_i + \\eta \\Delta w_i \\div m$ onde $\\eta$ é o learning rate e $m$ é o número de registros. Aqui esta a média que ajuda a reduzir qualquer grande variação nos dados de treinamento.\n",
    "- Repita para cada $e$ epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Links importantes\n",
    "\n",
    "- https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "- http://neuralnetworksanddeeplearning.com/\n",
    "- http://eli.thegreenplace.net/2016/understanding-gradient-descent/\n",
    "- https://www.khanacademy.org/math/ap-calculus-ab/derivative-introduction-ab/intro-to-diff-calculus-ab/v/newton-leibniz-and-usain-bolt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implementing the Hidden Layer\n",
    "\n",
    "Material de apoio\n",
    "\n",
    "- https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/vectors/v/vector-introduction-linear-algebra\n",
    "- https://www.khanacademy.org/math/precalculus/precalc-matrices\n",
    "\n",
    "\n",
    "### Derivação\n",
    "\n",
    "Ao lidar com multiplas intradas e camadas na rede neural, os pesos ($w$) vão precisar de 2 indices ($w_{ij}$)\n",
    "\n",
    "- i para unidades de entrada (input units)\n",
    "- j para unidades escondidas (hidden units)\n",
    "\n",
    "Assim, os pesos passam a ser representados como matrizes onde as linhas da matriz representão as unidades ocultas (hidden units) e as colunas as unidades de entrada.\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58a49908_multilayer-diagram-weights/multilayer-diagram-weights.png)\n",
    "\n",
    "Cada linha na matriz corresponderá aos pesos que saem de uma única unidade de entrada e cada coluna corresponderá aos pesos que conduzem a uma única unidade oculta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Como os pesos agora são representados na forma de matriz, para calcular a entrada para uma unidade oculta (hidden unit) precisamos a usar multiplicação de matrizes pois $h_j = \\sum_i w_{ij} x_i$\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/January/58895788_input-times-weights/input-times-weights.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\\begin{equation*}\n",
    "h_1 = x_1 w_{11} + x_2 w_{21} + x_3 w_{31}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Importante:** Com os pesos no formato de matriz, precisamos obedecer as regras de multiplicação de matrizes vistas anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Column Vector\n",
    "\n",
    "Devido as regras de multiplicação de matrizes, pode ser necessário transformar um array Numpy em uma coluna de vetores (column Vector). Para isso, veja os exemplos abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = np.array([0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1  0.2  0.3]\n"
     ]
    }
   ],
   "source": [
    "# Array Numpy\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1  0.2  0.3]\n"
     ]
    }
   ],
   "source": [
    "# Array transposto. Não atende\n",
    "print(features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1]\n",
      " [ 0.2]\n",
      " [ 0.3]]\n"
     ]
    }
   ],
   "source": [
    "# Coluna de vetores\n",
    "print(features[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exemplo\n",
    "\n",
    "Abaixo é aplicado uma rede neural com multiplas camadas como exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden-layer Output:\n",
      "[ 0.41492192  0.42604313  0.5002434 ]\n",
      "Output-layer Output:\n",
      "[ 0.49815196  0.48539772]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "# Network size\n",
    "N_input = 4\n",
    "N_hidden = 3\n",
    "N_output = 2\n",
    "\n",
    "np.random.seed(42)\n",
    "# Make some fake data\n",
    "X = np.random.randn(4)\n",
    "\n",
    "weights_input_to_hidden = np.random.normal(0, scale=0.1, size=(N_input, N_hidden))\n",
    "weights_hidden_to_output = np.random.normal(0, scale=0.1, size=(N_hidden, N_output))\n",
    "\n",
    "\n",
    "# TODO: Make a forward pass through the network\n",
    "\n",
    "# Aplica a soma linear das multiplicações entre entradas e pesos. O h das equações\n",
    "hidden_layer_in = np.dot(X, weights_input_to_hidden)\n",
    "\n",
    "# Aplica a step function que neste caso é a sigmoid\n",
    "hidden_layer_out = sigmoid(hidden_layer_in)\n",
    "\n",
    "print('Hidden-layer Output:')\n",
    "print(hidden_layer_out)\n",
    "\n",
    "# A saida do perceptron na hidden layer é a entrada do perceptron de saida.\n",
    "# Aplica a soma das mult. entre as entradas (saidas da camada anterior) aos pesos atribuidos a elas.\n",
    "output_layer_in = np.dot(hidden_layer_out, weights_hidden_to_output)\n",
    "\n",
    "# Aplica a step function (tbm a sigmoid) para obter a saida da rede neural.\n",
    "output_layer_out = sigmoid(output_layer_in)\n",
    "\n",
    "print('Output-layer Output:')\n",
    "print(output_layer_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Backpropagation\n",
    "\n",
    "Backpropagation é um algoritmo com a finalidade de encontrar o erro entre as camadas da rede neural.\n",
    "\n",
    "Com base no erro calculado na saída da rede neural, usa-se a função derivada e chain rule para obter a equação que calcula o erro nas camadas anteriores. Desta forma, o erro é propagado no sentido contrário da rede neural, posibilitanto o ajuste dos pesos em todas as camadas.\n",
    "\n",
    "Exemplo: Vamos calcular a saída de uma rede neural simples, com 2 entrada, 1 hidden layer e 1 output layer como na imagem abaixo:\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588bb45d_backprop-network/backprop-network.png)\n",
    "\n",
    "Vamos assumir que o valor target seja 1 ($y = 1$) seguimos os passos\n",
    "\n",
    "Vamos calcular o input para o hidden layer (já que as unidades de entrada são os valores em si). A equação para o calculo da entrada é $h = \\sum_i w_i x_i$ então:\n",
    "\n",
    "$h = (0.1 \\times 0.4) + (0.3 \\times -0.2) => 0.04 + (-0.06) = -0.02$\n",
    "\n",
    "Então passamos este valor pela função de ativação, neste caso a sigmoid ($sigmoid(h) = 1/(1 + e^{-h})$):\n",
    "\n",
    "$a = sigmoid(-0.02) => 1 / (1 + e^{-(-0.02)}) = 0.495$\n",
    "\n",
    "Então, 0.495 é a saída da hidden unit (um único perceptron) e é passado como a entrada do output unit (tbm um único perceptron). Assim, como temos apenas uma entrada, basta multiplicar o input com seu peso e aplicar a função de ativação sigmoid e assim obtemos a saída da rede neural:\n",
    "\n",
    "$h = 0.495 \\times 0.1 = 0.0495$\n",
    "\n",
    "$ŷ = sigmoid(0.0495) => 1 / (1 + e^{-0.0495}) = 0.512$\n",
    "\n",
    "Com base na saída da rede neural, podemos calcular o erro (error term) do output unit com a formula vista anteriormente $\\delta = (y - ŷ)*f'(h)$ lembrando que $h = \\sum_i w_i x_i$. Então temos:\n",
    "\n",
    "$\\delta = (y - ŷ) \\times f'(h)$\n",
    "\n",
    "$(y - ŷ) = (1 - 0.512) = 0.488$\n",
    "\n",
    "$sigmoid(h) = ŷ$\n",
    "\n",
    "$f'(h) = (sigmoid(h) \\times (1 - sigmoid(h))) = (0.512 \\times (1 - 0.512)) = 0.512 \\times 0.488 = 0.2498$\n",
    "\n",
    "$\\delta = 0.488 \\times 0.2498 = 0.122$\n",
    "\n",
    "Agora vamos calcular o error term para a hidden unit (neste caso, só termos um percptron na hidden layer) com backpropagation. Para isso vamos \"navegar\" na rede neural no sentido contrário e vamos passar para o hidden unit o error term da output unit (o erro final da rede):\n",
    "\n",
    "A equação usada é $\\delta_j^h = \\sum_k w_{jk} \\delta_k f'(h_j)$\n",
    "\n",
    "$\\delta^h = w \\delta f'(h_j) = 0.1 \\times 0.122 \\times f'(h) => 0.1 \\times 0.122 \\times 0.249 = 0.003$\n",
    "\n",
    "Onde:\n",
    "- 0.1 é o peso ($w$) entre a hidden unit e o output unit ($w$);\n",
    "- 0.122 é o error term da output unit ($\\delta$);\n",
    "- 0.249 é a derivada da função sigmoid de ativação ($f'(h)$)\n",
    "\n",
    "Agora, com o erro das output e hidden units podemos calcular o gradient descent. A variação do peso entre a hidden unit e output unit é calculado multiplicando o learning rate ($\\eta$) com o output error ($\\delta$) com o input desta unidade ($a$):\n",
    "\n",
    "$\\Delta w = \\eta \\delta a => 0.5 \\times 0.122 \\times 0.495 = 0.0302$\n",
    "\n",
    "Agora podemos calcular a variação dos pesos entre as input units e a hidden unit. Como temos 2 entradas, são gerados 2 valores.\n",
    "\n",
    "$\\Delta w_1 = \\eta \\delta^h x_1 => 0.5 \\times 0.003 \\times 0.1 = 0.00015$\n",
    "\n",
    "$\\Delta w_2 = \\eta \\delta^h x_2 => 0.5 \\times 0.003 \\times 0.3 = 0.00045$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in weights for hidden layer to output layer:\n",
      "[ 0.00804047  0.00555918]\n",
      "Change in weights for input layer to hidden layer:\n",
      "[[  1.77005547e-04  -5.11178506e-04]\n",
      " [  3.54011093e-05  -1.02235701e-04]\n",
      " [ -7.08022187e-05   2.04471402e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Este exercício esta muito ruim. Não é fácil \"mapear\" o exercício para o exemplo.\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "x = np.array([0.5, 0.1, -0.2])\n",
    "target = 0.6\n",
    "learnrate = 0.5\n",
    "\n",
    "weights_input_hidden = np.array([[0.5, -0.6],\n",
    "                                 [0.1, -0.2],\n",
    "                                 [0.1, 0.7]])\n",
    "\n",
    "weights_hidden_output = np.array([0.1, -0.3])\n",
    "\n",
    "## Forward pass\n",
    "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
    "hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "output = sigmoid(output_layer_in)\n",
    "\n",
    "## Backwards pass\n",
    "## TODO: Calculate error\n",
    "error = target - output\n",
    "\n",
    "# TODO: Calculate error gradient for output layer\n",
    "del_err_output = error * output * (1 - output)\n",
    "\n",
    "# TODO: Calculate error gradient for hidden layer\n",
    "del_err_hidden = np.dot(del_err_output, weights_hidden_output) * \\\n",
    "                 hidden_layer_output * (1 - hidden_layer_output)\n",
    "\n",
    "# TODO: Calculate change in weights for hidden layer to output layer\n",
    "delta_w_h_o = learnrate * del_err_output * hidden_layer_output\n",
    "\n",
    "# TODO: Calculate change in weights for input layer to hidden layer\n",
    "delta_w_i_h = learnrate * del_err_hidden * x[:, None]\n",
    "\n",
    "print('Change in weights for hidden layer to output layer:')\n",
    "print(delta_w_h_o)\n",
    "print('Change in weights for input layer to hidden layer:')\n",
    "print(delta_w_i_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Implementação do Backpropagation\n",
    "\n",
    "Formula do erro na camada de saída (saída da R.N./ output layer) é $\\delta_k = (y_k - ŷ_k) f'(a_k)$\n",
    "\n",
    "Formula do erro na camana oculta (hidden layer) é $\\delta_j = \\sum [w_{jk} \\delta_k] f'(h_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation passo a passo\n",
    "\n",
    "Considerando uma rede neural simples, com 1 camada oculta e uma unidade de saída, os passos para atualizar os pesos com backpropagation são:\n",
    "\n",
    "- Igualar a variação dos pesos a zero\n",
    " - Variação de peso entre entrada e camada oculta $\\Delta w_{ij} = 0$\n",
    " - Variação de peso entre camada oculta e saída da rede $\\Delta W_{j} = 0$\n",
    "\n",
    "- Para cada entrada nos dados de treinamento\n",
    " - Passar os valores pela rede para obter a saída (predição) da rede $ŷ$\n",
    " - Calcular o error gradient na unidade de saída, $\\deltaº = (y - ŷ) f'(z)$ onde $z = \\sum_j W_j a_j$, a entrada para a unidade de saída\n",
    " - Propagar os erros para a camada oculta $\\delta_j^h = \\delta^o W_j f'(h_j)$\n",
    " - Atualizar a variação dos pesos:\n",
    "   - $\\Delta W_j = \\Delta W_j + \\delta^o a_j$\n",
    "   - $\\Delta w_{ij} = \\Delta w_{ij} + \\delta_j^h a_i$\n",
    " \n",
    "- Atualizar os pesos apartir das variações dos pesos, onde $\\eta$ é a taxa de aprendizado e $m$ o número de registros\n",
    " - $W_j = W_j + \\eta \\Delta W_j / m$\n",
    " - $w_{ij} = w_{ij} + \\eta \\Delta w_{ij} / m$\n",
    "\n",
    "- Repedir\n",
    "\n",
    "### Links importantes\n",
    "\n",
    "- https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b\n",
    "- https://www.youtube.com/watch?v=59Hbtz7XgjM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
