{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Translation Invariance. Não importa onde o gato esta na imagem, só importa que é um gato na imagem. Para conseguir usar este conceito usamos **weight sharing**\n",
    "\n",
    "- Weight Sharing. Qndo 2 inputs tem o mesmo tipo de informação, seus pesos podem ser compartilhados e aprimora estes pesos juntos.\n",
    "\n",
    "## Convol. Networks (CNN)\n",
    "\n",
    "- ConNets compartilham seus pesos pelo espaço (alt, larg, profund.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step for a CNN is to break up the image into smaller pieces. We do this by selecting a width and height that defines a filter.\n",
    "\n",
    "The filter looks at small pieces, or patches, of the image. These patches are the same size as the filter.\n",
    "\n",
    "- **filter = patch = kernels**\n",
    "- **qdt filtros = filter depth**\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2016/November/58377d67_vlcsnap-2016-11-24-15h52m47s438/vlcsnap-2016-11-24-15h52m47s438.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's important here is that we are grouping together adjacent pixels and treating them as a collective.\n",
    "\n",
    "It's common to have more than one filter. Different filters pick up different qualities of a patch. For example, one filter might look for a particular color, while another might look for a kind of object of a specific shape. The amount of filters in a convolutional layer is called the filter depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Parameter Sharing\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2016/November/58377f77_vlcsnap-2016-11-24-16h01m35s262/vlcsnap-2016-11-24-16h01m35s262.png)\n",
    "\n",
    "The weights, w, are shared across patches for a given layer in a CNN to detect the cat above regardless of where in the image it is located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality\n",
    "\n",
    "Com as informações passadas podemos calcular o numero de neuronios paraca cada camada em uma CNN:\n",
    "\n",
    "- Nossa camada de entrada tem uma largura de W e uma altura de H\n",
    "- Nossa camada convolucional tem um tamanho de filtro F\n",
    "- Nós temos um passo (stride) de S\n",
    "- Um preenchimento (padding) de P\n",
    "- E o número de filtros K\n",
    "\n",
    "A seguinte fórmula nos dá a largura da próxima camada: $W_{out} = (W - F + 2P) / S + 1$\n",
    "\n",
    "A altura de saída seria $H_{out} = (H - F + 2P) / S + 1$\n",
    "\n",
    "E a profundidade de saída seria igual ao número de filtros $D_{out} = K$\n",
    "\n",
    "O volume de saída seria $W_{out} * H_{out} * D_{out}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1\n",
    "\n",
    "H = height, W = width, D = depth\n",
    "\n",
    "- We have an input of shape 32x32x3 (HxWxD)\n",
    "- 20 filters of shape 8x8x3 (HxWxD)\n",
    "- A stride of 2 for both the height and width (S)\n",
    "- With padding of size 1 (P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0\n"
     ]
    }
   ],
   "source": [
    "input_height = 32\n",
    "filter_height = 8\n",
    "P = 1\n",
    "S = 2\n",
    "\n",
    "new_height = (input_height - filter_height + 2 * P)/S + 1\n",
    "print(new_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0\n"
     ]
    }
   ],
   "source": [
    "input_width = 32\n",
    "filter_width = 8\n",
    "P = 1\n",
    "S = 2\n",
    "\n",
    "new_width = (input_width - filter_width + 2 * P)/S + 1\n",
    "print(new_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0 x 14.0 x 20\n"
     ]
    }
   ],
   "source": [
    "depth = 20\n",
    "\n",
    "output = '%s x %s x %s' % (new_height, new_width, depth)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando TensorFlow ficaria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "filter_weights = tf.Variable(tf.truncated_normal((8, 8, 3, 20))) # (height, width, input_depth, output_depth)\n",
    "filter_bias = tf.Variable(tf.zeros(20))\n",
    "strides = [1, 2, 2, 1] # (batch, height, width, depth)\n",
    "padding = 'SAME'\n",
    "conv = tf.nn.conv2d(input, filter_weights, strides, padding) + filter_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porem, o TensorFlow usa um algoritmo diferente, em suma as equações abaixo representam as opções 'SAME' e 'PADDING':\n",
    "\n",
    "SAME Padding, o output height e width são calculados como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_height = ceil(float(in_height) / float(strides1))\n",
    "\n",
    "out_width = ceil(float(in_width) / float(strides[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VALID Padding, o output height e width são calculados como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_height = ceil(float(in_height - filter_height + 1) / float(strides1))\n",
    "\n",
    "out_width = ceil(float(in_width - filter_width + 1) / float(strides[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2\n",
    "\n",
    "Com o output layer do Quiz 1 calcule a quantidade de parametros esta CNN teria sem compartilhamento de parametros. (Sem o compartilhamento de parâmetros, cada neurônio na camada de saída deve se conectar a cada neurônio no filtro. Além disso, cada neurônio na camada de saída também deve se conectar a um único neurônio de bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756560\n"
     ]
    }
   ],
   "source": [
    "out_put_layer_neurons = 14*14*20\n",
    "\n",
    "filter_neuros = 8*8*3\n",
    "\n",
    "bias_neurons = out_put_layer_neurons\n",
    "\n",
    "total_parameters = (out_put_layer_neurons * filter_neuros) + bias_neurons\n",
    "\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 3\n",
    "\n",
    "Como o mesmos parametros do Quiz 1, calcular o total de parametros **com** compartilhamento de parametros. (Com o compartilhamento de parâmetros, cada neurônio em um canal de saída compartilha seus pesos com cada outro neurônio nesse canal. Assim, o número de parâmetros é igual ao número de neurônios no filtro, mais um neurônio de polarização, todos multiplicados pelo número de canais na camada de saída.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3860\n"
     ]
    }
   ],
   "source": [
    "output_channels = 20\n",
    "\n",
    "filter_neuros = 8*8*3\n",
    "\n",
    "total_parameters = output_channels * (filter_neuros + 1)\n",
    "\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo em TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image Properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=[None, image_height, image_width, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal(\n",
    "    [filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Apply Convolution\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# Apply activation function\n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código acima usa a função tf.nn.conv2d() para calcular a convolução com **peso** como filtro e **[1, 2, 2, 1]** para os passos. TensorFlow usa um *stride* para cada dimensão de **entrada**, *[batch, input_height, input_width, input_channels]*. Geralmente, sempre vamos definir o *stride* para o *batch* e *input_channels* (ou seja, o primeiro eo quarto elemento na matriz strides) para ser 1.\n",
    "\n",
    "Você se concentrará em alterar *input_height* e *input_width* enquanto define *batch* e *input_channels* como 1. Os strides *input_height* e *input_width* são para passar o filtro pela *entrada*. Este código de exemplo usa um stride de 2 com filtro 5x5 sobre *entrada*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CovNet Avançado\n",
    "\n",
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2016/November/581a58be_convolution-schematic/convolution-schematic.gif)\n",
    "\n",
    "Abaixo são listados alguns métodos para aprimorar uma CNN.\n",
    "\n",
    "- Pooling - Usado para reduzir as dimesões espaciais (down-sampling) dos dados de input, enquanto contribui para evitar o overfitting. Geralmente aplicado entre camadas \"convolution\".\n",
    "\n",
    "Recentemente, pooling layers perderam a preferencia por algumas razões:\n",
    "\n",
    "    - Os datasets recentes são tão grandes e complexos que o que mais preocupa é o underfittig; \n",
    "    - Dropout é um regularizador melhor\n",
    "    - Polling resulta em perda de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "conv_layer = tf.nn.relu(conv_layer)\n",
    "# Apply Max Pooling\n",
    "conv_layer = tf.nn.max_pool(\n",
    "    conv_layer,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1x1 convolutions - Tbm usado para reduzir dimensões especiais. Atua na redução das dimesões do filtro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inception - Em cada camada da CNN podemos escolher entre vária opções a aplicar, 1x1 conv, 3x3 conv, 5x5 conv, pooling etc. Qual escolher? Inception module usa todas as opções e concatena suas saídas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Quiz 4\n",
    "\n",
    "Configurar a CNN para, a partir de um input (1,4,4,1), dar um output (1,2,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_1:0\", shape=(1, 2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Setup the strides, padding and filter weight/bias such that\n",
    "the output shape is (1, 2, 2, 3).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
    "    F_W = tf.Variable(tf.random_normal([4, 4, 1, 3]))\n",
    "    F_b = tf.Variable(tf.zeros(3))\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'SAME'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n",
    "\n",
    "print(conv2d(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 5\n",
    "\n",
    "No exercício abaixo, você será solicitado a configurar as dimensões dos filtros de agrupamento, passadas, bem como o preenchimento apropriado. Você deve consultar a documentação do TensorFlow para tf.nn.max_pool (). Padding funciona da mesma forma que faz para uma convolução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool:0\", shape=(1, 2, 2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set the values to `strides` and `ksize` such that\n",
    "the output shape after pooling is (1, 2, 2, 1).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.max_pool` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "def maxpool(input):\n",
    "    # TODO: Set the ksize (filter size) for each dimension (batch_size, height, width, depth)\n",
    "    ksize = [1, 2, 2, 1]\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'SAME'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#max_pool\n",
    "    return tf.nn.max_pool(input, ksize, strides, padding)\n",
    "    \n",
    "print(maxpool(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fontes adicionais\n",
    "\n",
    "These are the resources we recommend in particular:\n",
    "\n",
    "- Andrej Karpathy's [CS231n Stanford course](http://cs231n.github.io/) on Convolutional Neural Networks.\n",
    "- Michael Nielsen's [free book](http://neuralnetworksanddeeplearning.com/) on Deep Learning.\n",
    "- Goodfellow, Bengio, and Courville's more advanced [free book](http://deeplearningbook.org/) on Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
