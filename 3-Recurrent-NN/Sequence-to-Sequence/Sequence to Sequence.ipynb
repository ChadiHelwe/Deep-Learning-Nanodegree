{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquiteturas possíveis numa rede RNN:\n",
    "\n",
    "![](http://karpathy.github.io/assets/rnn/diags.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many to one foi usuada na aula de análise de sentimentos do Mat. Para modelos de tradução ou chat bot, por ex, são usados modelos many to many. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo seq-to-seq é baseado em 2 RNN ligadas. Uma dela processa o input e é chamada de **Encoder**. A segunda, chamada **Decoder**, recebe a saída do Encode e gera o output do modelo. Esta comunicação entre as redes é chamada de **state** ou **context**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este processo pode ser representado com o fluxo abaixo:\n",
    "\n",
    "![](encoder-decoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vemos que cada palavra é vetorizada, como nos exemplos anteriores de RNN, e é passada para a unidade Encoder. Esta processa a sequencia de palavras compartilhando o hidden state entre os time steps.\n",
    "\n",
    "Ao final, a unidade Encoder transfere seu hidden state (contexto ou estado) para a unodade Decoder que a processa da mesma forma (como uma RNN).\n",
    "\n",
    "Ao final ficam as camadas fully connected para gerar os outputs. **São logits em mesmo número que o vocabulário**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq to Seq in Tensorflow\n",
    "\n",
    "O Tensorflow possui um monte de APIs que ajudam a criar um modelo de sequência (também chamado de modelo seq2seq). É importante notar que essas APIs mudaram no final de 2016 (e de certa forma ainda estão evoluindo). Muitos dos tutoriais que você encontrará na web para seq2seq no tensorflow usam o tf.contrib.legacy_seq2seq (anteriormente chamado de \"tf.nn.seq2seq\").\n",
    "\n",
    "Os módulos de nota para seq2seq são: \n",
    "\n",
    "- tf.nn, o que nos permite construir diferentes tipos de RNNs\n",
    "- ff.contrib.rnn, que define um número de células RNN (uma célula RNN é um parâmetro necessário para as RNNs definidas em tf.nn).\n",
    "- tf.contrib.seq2seq, que contém decodificadores seq2seq e operações de perda.\n",
    "\n",
    "\n",
    "- Encoder: tf.nn.dynamic_rnn.\n",
    "- Decoder: tf.contrib.seq2seq.dynamic_rnn_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq to understand its major component. You can ignore everything with “attention” for the time being."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More resources\n",
    "\n",
    "- [tensorflow-seq2seq-tutorials](https://github.com/ematvey/tensorflow-seq2seq-tutorials) has a working version of the current TensorFlow seq2seq APIs\n",
    "- [Cornell Movie--Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html) is a dataset of conversations extracted from movie scripts\n",
    "- [tf-stanford-tutorials](https://github.com/chiphuyen/tf-stanford-tutorials/tree/master/assignments/chatbot) has an script that preprocesses the Cornell corpus\n",
    "- [DEEP LEARNING FOR CHATBOTS](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/)\n",
    "- [Sequence to Sequence Deep Learning (Quoc Le, Google)](https://www.youtube.com/watch?v=G5RY_SUJih4) - Incredible talk. Uses a solid example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
